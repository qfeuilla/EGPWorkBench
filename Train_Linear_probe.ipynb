{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbbReyvrX7pT"
      },
      "source": [
        "# Imports and utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vuvdDqHjO5T"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "\n",
        "from typing import List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DRmpGC9JaR0"
      },
      "outputs": [],
      "source": [
        "import einops\n",
        "import numpy as np\n",
        "# from torchvision import transforms\n",
        "# from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7-9jxGWjWCH"
      },
      "outputs": [],
      "source": [
        "from common.model_target import ImpalaModelTarget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43WGycDtIhJP"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqMevJ5UYNoO"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yjhh0KDVY04P"
      },
      "source": [
        "## Load data locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEcTlU9FBkP3"
      },
      "outputs": [],
      "source": [
        "def get_rewarded_obs_idxs(rew_batch: torch.Tensor, \n",
        "                          done_batch: torch.Tensor\n",
        "                         ) -> torch.Tensor:\n",
        "  sliced = torch.clone(rew_batch)\n",
        "  for r in range(sliced.shape[0]):\n",
        "    start = 0\n",
        "    for i in torch.nonzero(done_batch[r]):\n",
        "        sliced[r][start:i] = rew_batch[r][i]\n",
        "        start = i + 1\n",
        "  return torch.nonzero(sliced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzRKjJj8AfIi"
      },
      "outputs": [],
      "source": [
        "# def collect_obs(dir: str, n_epochs: int) -> torch.Tensor:\n",
        "#     obs = []\n",
        "#     for e in range(1, n_epochs + 1):\n",
        "#         print(f'Epoch: {e}')\n",
        "#         rew_batch = torch.load(os.path.join(dir, str(e), 'rew_batch.pt'), map_location=device)\n",
        "#         done_batch = torch.load(os.path.join(dir, str(e), 'done_batch.pt'), map_location=device)\n",
        "#         obs_idxs = get_rewarded_obs_idxs(rew_batch, done_batch)\n",
        "#         print('collect obs idxs')\n",
        "\n",
        "#         tmp_obs = torch.load(os.path.join(dir, str(e), 'observations_batch.pt'), map_location=device)[obs_idxs]\n",
        "#         print('load obs')\n",
        "#         #tmp_obs = torch.quantize_per_tensor_dynamic(tmp_obs, dtype=torch.quint8, reduce_range=True)\n",
        "#         print('quantize obs')\n",
        "#         obs.append(tmp_obs)\n",
        "    \n",
        "#     return torch.stack(obs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = \"samples\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AydFSjZTY3-P"
      },
      "source": [
        "## Create Dataset\n",
        "- [ ] Load data  \n",
        "- [ ] Generate wrong target twin "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtC4gZsfRE1x"
      },
      "outputs": [],
      "source": [
        "def get_target_idx(targets: torch.Tensor) -> Tuple[List[int], torch.Tensor]:\n",
        "    target_asset = targets.unique(dim=1)\n",
        "    target_idxs = []\n",
        "    for t in targets[0]:\n",
        "        for i in range(target_asset.shape[0]):\n",
        "            if torch.all(target_asset[0][i].eq(t)):\n",
        "                target_idxs.append(i)\n",
        "                break\n",
        "    return target_idxs, target_asset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_tensor(path: str):\n",
        "    t = torch.load(path)\n",
        "    return einops.rearrange(t, 'step env -> env step')\n",
        "\n",
        "def load_img(path: str):\n",
        "    t = torch.load(path)\n",
        "    return einops.rearrange(t, 'step env c w h -> env step c w h')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtYtJfY3J1mB"
      },
      "outputs": [],
      "source": [
        "class ProbingDataset(Dataset):\n",
        "    def __init__(self, dir:str, n_dir:int = 1, transform=None, target_transform=None) -> None:\n",
        "        self.path = os.path.join(dir, str(n_dir))\n",
        "\n",
        "        self.rewards = load_tensor(os.path.join(self.path, 'rew_batch.pt'))\n",
        "        self.dones = load_tensor(os.path.join(self.path, 'done_batch.pt'))\n",
        "\n",
        "        self.obs_idxs = get_rewarded_obs_idxs(self.rewards, self.dones)\n",
        "        self.observations = load_img(os.path.join(self.path, 'observations_batch.pt'))\n",
        "        self.observations = self.observations[obs_idx]\n",
        "\n",
        "        # Flatten the samples\n",
        "        self.rewards = einops.rearrange(self.rewards, \"env step -> (env step)\")\n",
        "        self.observations = einops.rearrange(self.observations, \"env step c w h -> (env step) c w h\")\n",
        "\n",
        "        targets = load_img(os.path.join(self.path, 'target_idxs.pt'))\n",
        "        self.target_idxs, self.target_assets = get_target_idx(targets)\n",
        "        \n",
        "        del self.dones\n",
        "        del targets\n",
        "\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.rewards.shape[0])\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        obs = self.observations[idx]\n",
        "        target_id = self.target_idxs[idx % 257] # WARNING: not sure :'(\n",
        "\n",
        "        true_target = np.random.rand(1)[0] > .5\n",
        "        if true_target:\n",
        "            target = self.target_assets[idx]\n",
        "            reward = self.rewards[idx] \n",
        "        else: \n",
        "            targets_probas = np.ones(26) * .04\n",
        "            targets_probas[target_id] = 0\n",
        "            target = self.target_assets[np.random.choice(26, size=1, p=targets_probas)]\n",
        "            reward = self.reward[idx] * -1 \n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return obs, target, reward\n",
        "\n",
        "    # def get_rewarded_obs_idxs(self) -> torch.Tensor:\n",
        "    #     sliced = torch.clone(self.reward)\n",
        "    #     for j in range(self.reward.shape[0]):\n",
        "    #       for r in range(sliced.shape[1]):\n",
        "    #         start = 0\n",
        "    #         for i in torch.nonzero(self.done[j][r]):\n",
        "    #             sliced[j][r][start:i] = self.reward[j][r][i]\n",
        "    #             start = i + 1\n",
        "    #     return torch.nonzero(sliced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WptQ854zYW93"
      },
      "source": [
        "# Load Impala Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXkxjT47EO99"
      },
      "outputs": [],
      "source": [
        "model_path = \"logs/procgen/coinrun/easy-random-100-res-128-coins-27-pierre-old/seed_3087_15-12-2022_11-01-44/model_31031296.pth\" #FIXME\n",
        "tmp_dict = torch.load(model_path, map_location=device)[\"state_dict\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Update the state_dict to fit the .embedder instead of the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kn15iQaaGJ0e"
      },
      "outputs": [],
      "source": [
        "del tmp_dict['fc_policy.weight']\n",
        "del tmp_dict['fc_policy.bias']\n",
        "del tmp_dict['fc_value.weight']\n",
        "del tmp_dict['fc_value.bias']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyqPrSy0GfJZ"
      },
      "outputs": [],
      "source": [
        "state_dict = {}\n",
        "for key, value in tmp_dict.items():\n",
        "  state_dict[key.replace('embedder.', '')] = tmp_dict[key]\n",
        "\n",
        "del tmp_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKbio71tH2oM",
        "outputId": "e3b0ca15-051f-44fc-c2de-af6f6574c516"
      },
      "outputs": [],
      "source": [
        "impala_model = ImpalaModelTarget(in_channels=3)\n",
        "impala_model.load_state_dict(state_dict)\n",
        "impala_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh3uR_8tYynY"
      },
      "source": [
        "# Create Linear probe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA8jbtgFZNaZ"
      },
      "source": [
        "## Linear probe architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hau1nfo5dTBP"
      },
      "outputs": [],
      "source": [
        "class LinearProbe(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim) -> None:\n",
        "    super().__init__()\n",
        "    self.clf = nn.Linear(in_features=input_dim, out_features=output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.clf(x)\n",
        "    x = F.sigmoid(x)\n",
        "    return self.clf()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vnn9QrH1dIus"
      },
      "outputs": [],
      "source": [
        "class ProbedModel(nn.Module):\n",
        "  def __init__(self, model: nn.Module) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    self.model = model\n",
        "    self.model.requires_grad_(False)\n",
        "    self.probe = LinearProbe(\n",
        "        input_dim=self.model.fc1.in_features,\n",
        "        output_dim=1\n",
        "    )\n",
        "\n",
        "  def forward(self, x, target) -> torch.Tensor:\n",
        "    hidden = self.model.forward(x, target)\n",
        "    return self.probe(hidden)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UFvzk-XZWVX"
      },
      "source": [
        "# Train Linear Probe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xP3EqGpJjWzt"
      },
      "outputs": [],
      "source": [
        "def train(model: nn.Module, dir: str, \n",
        "          epochs: int, lr: int, regularization=None\n",
        "          ) -> List[int]:\n",
        "\n",
        "  assert(model.model.requires_grad == False)\n",
        "\n",
        "  loss_fn = nn.MSELoss()\n",
        "  loss_hist = []\n",
        "  optimizer = Adam(model.parameters(), lr=lr)\n",
        "  \n",
        "  for i in range(epochs):\n",
        "    random_dir = np.random.randint(1, 41)\n",
        "    dataset = ProbingDataset(dir=dir, n_dir=random_dir)\n",
        "    dataloader = DataLoader(dataset)\n",
        "    for sample in dataloader:\n",
        "      optimizer.zero_grad()\n",
        "      obs, target, y = sample\n",
        "      y_pred = model(obs, target)\n",
        "      loss = loss_fn(y_pred, y)\n",
        "\n",
        "      if regularization == \"L1\":\n",
        "        l1_loss = torch.abs(model.probe.parameters).sum()\n",
        "        loss = loss + l1_loss\n",
        "\n",
        "      loss.backward()\n",
        "      loss_hist.append(loss)\n",
        "\n",
        "  return loss_hist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWGo8iPun0W2"
      },
      "outputs": [],
      "source": [
        "model = ProbedModel(model=impala_model)\n",
        "\n",
        "loss_hist = train(model, dir=\"samples\", epochs=50, lr=...) #FIXME "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "observations = torch.load(\"/home/qfeuilla/Desktop/AI Safety/Explicit_Goal_Pointer/EGPWorkBench/samples/1/observations_batch.pt\")\n",
        "rewards = torch.load(\"/home/qfeuilla/Desktop/AI Safety/Explicit_Goal_Pointer/EGPWorkBench/samples/1/rew_batch.pt\")\n",
        "targets = torch.load(\"/home/qfeuilla/Desktop/AI Safety/Explicit_Goal_Pointer/EGPWorkBench/samples/1/target_idxs.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(torch.nonzero(rewards))):\n",
        "    plt.imshow(einops.rearrange(observations[torch.nonzero(rewards)[i][0]][torch.nonzero(rewards)[i][1]], 'c w h -> w h c'))\n",
        "    plt.show()\n",
        "    plt.imshow(einops.rearrange(targets[torch.nonzero(rewards)[i][0]][torch.nonzero(rewards)[i][1]], 'c w h -> w h c'))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "egp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "2c578b1ca8798f44f2eb0c6a4b34dbe24febf8932c2b3d83aa592cd1007972ce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
